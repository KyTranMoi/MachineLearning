{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 1\n",
    "**Giải Thuật Apriori**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các tập mặt hàng phổ biến:\n",
      "Kích thước 1: [frozenset({'butter'}), frozenset({'milk'}), frozenset({'bread'})]\n",
      "Kích thước 2: [frozenset({'butter', 'milk'}), frozenset({'butter', 'bread'}), frozenset({'bread', 'milk'})]\n",
      "Kích thước 3: [frozenset({'butter', 'bread', 'milk'})]\n",
      "Kích thước 4: []\n",
      "\n",
      "Dữ liệu hỗ trợ:\n",
      "frozenset({'butter'}): 0.8\n",
      "frozenset({'milk'}): 0.8\n",
      "frozenset({'bread'}): 0.8\n",
      "frozenset({'butter', 'milk'}): 0.6\n",
      "frozenset({'butter', 'bread'}): 0.6\n",
      "frozenset({'bread', 'milk'}): 0.6\n",
      "frozenset({'butter', 'bread', 'milk'}): 0.4\n",
      "Các luật kết hợp:\n",
      "['milk'] => ['butter'] (Confidence: 0.7499999999999999)\n",
      "['butter'] => ['milk'] (Confidence: 0.7499999999999999)\n",
      "['bread'] => ['butter'] (Confidence: 0.7499999999999999)\n",
      "['butter'] => ['bread'] (Confidence: 0.7499999999999999)\n",
      "['milk'] => ['bread'] (Confidence: 0.7499999999999999)\n",
      "['bread'] => ['milk'] (Confidence: 0.7499999999999999)\n",
      "['bread', 'milk'] => ['butter'] (Confidence: 0.6666666666666667)\n",
      "['butter', 'milk'] => ['bread'] (Confidence: 0.6666666666666667)\n",
      "['butter', 'bread'] => ['milk'] (Confidence: 0.6666666666666667)\n"
     ]
    }
   ],
   "source": [
    "# Hàm để tạo các mục phổ biến kích thước 1 từ tập dữ liệu\n",
    "def create_candidates(data):\n",
    "    candidates = set()\n",
    "    for transaction in data:\n",
    "        for item in transaction:\n",
    "            candidates.add(frozenset([item]))\n",
    "    return candidates\n",
    "\n",
    "# Hàm để loại bỏ các mục không phổ biến\n",
    "def prune_candidates(candidates, data, min_support):\n",
    "    candidate_counts = {}\n",
    "    for transaction in data:\n",
    "        for candidate in candidates:\n",
    "            if candidate.issubset(transaction):\n",
    "                candidate_counts[candidate] = candidate_counts.get(candidate, 0) + 1\n",
    "\n",
    "    num_transactions = len(data)\n",
    "    frequent_candidates = []\n",
    "    support_data = {}\n",
    "    for candidate, count in candidate_counts.items():\n",
    "        support = count / num_transactions\n",
    "        if support >= min_support:\n",
    "            frequent_candidates.append(candidate)\n",
    "        support_data[candidate] = support\n",
    "\n",
    "    return frequent_candidates, support_data\n",
    "\n",
    "# Hàm để tạo các tập ứng viên mới từ các tập phổ biến cũ\n",
    "def create_new_candidates(old_candidates, k):\n",
    "    new_candidates = []\n",
    "    num_old_candidates = len(old_candidates)\n",
    "    for i in range(num_old_candidates):\n",
    "        for j in range(i + 1, num_old_candidates):\n",
    "            itemset1 = list(old_candidates[i])[:k - 2]\n",
    "            itemset2 = list(old_candidates[j])[:k - 2]\n",
    "            itemset1.sort()\n",
    "            itemset2.sort()\n",
    "            if itemset1 == itemset2:\n",
    "                new_candidates.append(old_candidates[i] | old_candidates[j])\n",
    "    return new_candidates\n",
    "\n",
    "# Hàm chính để thực hiện giải thuật Apriori\n",
    "def apriori(data, min_support):\n",
    "    candidates = create_candidates(data)\n",
    "    frequent_items, support_data = prune_candidates(candidates, data, min_support)\n",
    "    all_frequent_items = [frequent_items]\n",
    "    k = 2\n",
    "    while len(all_frequent_items[-1]) > 0:\n",
    "        new_candidates = create_new_candidates(all_frequent_items[-1], k)\n",
    "        frequent_items, new_support_data = prune_candidates(new_candidates, data, min_support)\n",
    "        support_data.update(new_support_data)\n",
    "        all_frequent_items.append(frequent_items)\n",
    "        k += 1\n",
    "    return all_frequent_items, support_data\n",
    "data = [['milk', 'bread', 'butter'],\n",
    "        ['milk', 'bread'],\n",
    "        ['milk', 'butter'],\n",
    "        ['milk', 'bread', 'butter'],\n",
    "        ['bread', 'butter']]\n",
    "\n",
    "min_support = 0.1\n",
    "\n",
    "frequent_itemsets, support_data = apriori(data, min_support)\n",
    "\n",
    "print(\"Các tập mặt hàng phổ biến:\")\n",
    "for k, itemsets in enumerate(frequent_itemsets):\n",
    "    print(f\"Kích thước {k+1}: {itemsets}\")\n",
    "\n",
    "print(\"\\nDữ liệu hỗ trợ:\")\n",
    "for itemset, support in support_data.items():\n",
    "    print(f\"{itemset}: {support}\")\n",
    "# in tập luật kết hợp\n",
    "def generate_rules(frequent_itemsets, support_data, min_confidence):\n",
    "    rules = []\n",
    "    for k_itemset in frequent_itemsets[1:]:\n",
    "        for itemset in k_itemset:\n",
    "            for item in itemset:\n",
    "                antecedent = itemset - set([item])\n",
    "                consequent = set([item])\n",
    "                confidence = support_data[itemset] / support_data[antecedent]\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append((antecedent, consequent, confidence))\n",
    "    return rules\n",
    "min_confidence = 0.5\n",
    "rules = generate_rules(frequent_itemsets, support_data, min_confidence)\n",
    "# In ra các luật kết hợp\n",
    "print(\"Các luật kết hợp:\")\n",
    "for antecedent, consequent, confidence in rules:\n",
    "    print(f\"{list(antecedent)} => {list(consequent)} (Confidence: {confidence})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support               itemsets\n",
      "0      0.8                (bread)\n",
      "1      0.8               (butter)\n",
      "2      0.8                 (milk)\n",
      "3      0.6        (butter, bread)\n",
      "4      0.6          (bread, milk)\n",
      "5      0.6         (butter, milk)\n",
      "6      0.4  (butter, bread, milk)\n",
      "['butter'] => ['bread'] (Confidence: 0.7499999999999999)\n",
      "['bread'] => ['butter'] (Confidence: 0.7499999999999999)\n",
      "['bread'] => ['milk'] (Confidence: 0.7499999999999999)\n",
      "['milk'] => ['bread'] (Confidence: 0.7499999999999999)\n",
      "['butter'] => ['milk'] (Confidence: 0.7499999999999999)\n",
      "['milk'] => ['butter'] (Confidence: 0.7499999999999999)\n",
      "['butter', 'bread'] => ['milk'] (Confidence: 0.6666666666666667)\n",
      "['butter', 'milk'] => ['bread'] (Confidence: 0.6666666666666667)\n",
      "['bread', 'milk'] => ['butter'] (Confidence: 0.6666666666666667)\n",
      "['butter'] => ['bread', 'milk'] (Confidence: 0.5)\n",
      "['bread'] => ['butter', 'milk'] (Confidence: 0.5)\n",
      "['milk'] => ['butter', 'bread'] (Confidence: 0.5)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "\n",
    "encoder = TransactionEncoder()\n",
    "transactions_encoded = encoder.fit(data).transform(data)\n",
    "df = pd.DataFrame(transactions_encoded, columns=encoder.columns_)\n",
    "frequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\n",
    "print(frequent_itemsets)\n",
    "#in ra các  luật kết hợp\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "for i in rules.index:\n",
    "    if rules.iloc[i]['confidence'] >= min_confidence:\n",
    "        print(f\"{list(rules.iloc[i]['antecedents'])} => {list(rules.iloc[i]['consequents'])} (Confidence: {rules.iloc[i]['confidence']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FP-Growth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ hỗ trợ của các tập mặt hàng phổ biến:\n",
      "{'butter'}: 0.8\n",
      "{'bread'}: 0.8\n",
      "{'butter', 'bread'}: 0.6\n",
      "{'milk'}: 0.8\n",
      "{'butter', 'milk'}: 0.6\n",
      "{'bread', 'milk'}: 0.6\n",
      "{'butter', 'bread', 'milk'}: 0.4\n"
     ]
    }
   ],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, item, frequency, parent):\n",
    "        self.item = item\n",
    "        self.frequency = frequency\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "        self.next_link = None\n",
    "\n",
    "def construct_tree(dataset, min_support):\n",
    "    header_table = {}\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            header_table[item] = header_table.get(item, 0) + dataset[transaction]\n",
    "\n",
    "    for item in list(header_table.keys()):\n",
    "        if header_table[item] < min_support:\n",
    "            del(header_table[item])\n",
    "\n",
    "    frequent_items = set(header_table.keys())\n",
    "\n",
    "    if len(frequent_items) == 0:\n",
    "        return None, None\n",
    "\n",
    "    for item in header_table:\n",
    "        header_table[item] = [header_table[item], None]\n",
    "\n",
    "    fp_tree = TreeNode(\"Null\", 1, None)\n",
    "    for transaction, frequency in dataset.items():\n",
    "        transaction_sorted = []\n",
    "        for item in transaction:\n",
    "            if item in frequent_items:\n",
    "                transaction_sorted.append(item)\n",
    "        if len(transaction_sorted) > 0:\n",
    "            update_tree(fp_tree, transaction_sorted, header_table, frequency)\n",
    "\n",
    "    return fp_tree, header_table\n",
    "\n",
    "def update_tree(current_node, transaction_sorted, header_table, frequency):\n",
    "    if transaction_sorted[0] in current_node.children:\n",
    "        current_node.children[transaction_sorted[0]].frequency += frequency\n",
    "    else:\n",
    "        current_node.children[transaction_sorted[0]] = TreeNode(transaction_sorted[0], frequency, current_node)\n",
    "\n",
    "        if header_table[transaction_sorted[0]][1] is None:\n",
    "            header_table[transaction_sorted[0]][1] = current_node.children[transaction_sorted[0]]\n",
    "        else:\n",
    "            update_header(header_table[transaction_sorted[0]][1], current_node.children[transaction_sorted[0]])\n",
    "\n",
    "    if len(transaction_sorted) > 1:\n",
    "        update_tree(current_node.children[transaction_sorted[0]], transaction_sorted[1:], header_table, frequency)\n",
    "\n",
    "def update_header(node_to_test, target_node):\n",
    "    while node_to_test.next_link is not None:\n",
    "        node_to_test = node_to_test.next_link\n",
    "    node_to_test.next_link = target_node\n",
    "\n",
    "def ascend_tree(node, prefix_path):\n",
    "    if node.parent is not None:\n",
    "        prefix_path.append(node.item)\n",
    "        ascend_tree(node.parent, prefix_path)\n",
    "\n",
    "def find_prefix_path(base_item, header_table):\n",
    "    tree_node = header_table[base_item][1]\n",
    "    prefix_paths = {}\n",
    "    while tree_node is not None:\n",
    "        prefix_path = []\n",
    "        ascend_tree(tree_node, prefix_path)\n",
    "        if len(prefix_path) > 1:\n",
    "            prefix_paths[frozenset(prefix_path[1:])] = tree_node.frequency\n",
    "        tree_node = tree_node.next_link\n",
    "    return prefix_paths\n",
    "\n",
    "def mine_patterns(header_table, min_support, prefix, frequent_itemsets):\n",
    "    bigL = [v[0] for v in sorted(header_table.items(), key=lambda p: p[1][0])]\n",
    "\n",
    "    for base_item in bigL:\n",
    "        new_frequent_set = prefix.copy()\n",
    "        new_frequent_set.add(base_item)\n",
    "        frequent_itemsets.append(new_frequent_set)\n",
    "        conditional_tree_paths = find_prefix_path(base_item, header_table)\n",
    "        conditional_tree, conditional_header = construct_tree(conditional_tree_paths, min_support)\n",
    "        if conditional_header is not None:\n",
    "            mine_patterns(conditional_header, min_support, new_frequent_set, frequent_itemsets)\n",
    "\n",
    "def fpgrowth(dataset, min_support):\n",
    "    fp_tree, header_table = construct_tree(dataset, min_support)\n",
    "    frequent_itemsets = []\n",
    "    mine_patterns(header_table, min_support, set([]), frequent_itemsets)\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Tạo tập dữ liệu mẫu\n",
    "data = [['milk', 'bread', 'butter'],\n",
    "        ['milk', 'bread'],\n",
    "        ['milk', 'butter'],\n",
    "        ['milk', 'bread', 'butter'],\n",
    "        ['bread', 'butter']]\n",
    "\n",
    "# Đếm tần suất xuất hiện của mỗi giao dịch\n",
    "transaction_counts = {}\n",
    "for transaction in data:\n",
    "    transaction_counts[frozenset(transaction)] = transaction_counts.get(frozenset(transaction), 0) + 1\n",
    "\n",
    "# Áp dụng giải thuật FP-Growth\n",
    "min_support = 2  # Số lần xuất hiện tối thiểu\n",
    "frequent_itemsets = fpgrowth(transaction_counts, min_support)\n",
    "\n",
    "print(\"Độ hỗ trợ của các tập mặt hàng phổ biến:\")\n",
    "for itemset in frequent_itemsets:\n",
    "    support = support_data[frozenset(itemset)]\n",
    "    print(f\"{itemset}: {support}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các luật kết hợp:\n",
      "frozenset({'butter'}) => {'bread'} (Confidence: 0.7499999999999999)\n",
      "frozenset({'bread'}) => {'butter'} (Confidence: 0.7499999999999999)\n",
      "frozenset({'butter'}) => {'milk'} (Confidence: 0.7499999999999999)\n",
      "frozenset({'milk'}) => {'butter'} (Confidence: 0.7499999999999999)\n",
      "frozenset({'bread'}) => {'milk'} (Confidence: 0.7499999999999999)\n",
      "frozenset({'milk'}) => {'bread'} (Confidence: 0.7499999999999999)\n"
     ]
    }
   ],
   "source": [
    "def generate_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            rules.extend(generate_rules_from_itemset(itemset, min_confidence))\n",
    "    return rules\n",
    "\n",
    "def generate_rules_from_itemset(itemset, min_confidence):\n",
    "    rules = []\n",
    "    for item in itemset:\n",
    "        antecedent = frozenset([item])\n",
    "        consequent = itemset - antecedent\n",
    "        confidence = support_data[frozenset(itemset)] / support_data[antecedent]\n",
    "        if confidence >= min_confidence:\n",
    "            rules.append((antecedent, consequent, confidence))\n",
    "    return rules\n",
    "\n",
    "# In ra các luật kết hợp\n",
    "min_confidence = 0.7  # Ngưỡng độ tin cậy tối thiểu\n",
    "rules = generate_rules(frequent_itemsets, min_confidence)\n",
    "\n",
    "print(\"Các luật kết hợp:\")\n",
    "for antecedent, consequent, confidence in rules:\n",
    "    print(f\"{antecedent} => {consequent} (Confidence: {confidence})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lớp Node đại diện cho một nút trong cây. Mỗi nút có một tên (name), trọng số (weight), nút cha (parent) và một từ điển chứa các nút con (children).\n",
    "\n",
    "Lớp SWNTree đại diện cho cây dựa trên cửa sổ trượt. Nó có một nút gốc (root), một phương thức insert_tree để chèn một giao dịch T vào cây R, một phương thức tw để tính toán trọng số của một giao dịch (được để trống và cần được triển khai), và một phương thức construct để xây dựng cây từ một cơ sở dữ liệu DB.\n",
    "\n",
    "Phương thức construct sắp xếp các mục trong mỗi giao dịch T theo tần suất trong cửa sổ hiện tại, sau đó chèn T vào cây bằng cách gọi phương thức insert_tree. Cuối cùng, nó trả về nút gốc của cây.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null (weight: 0, pre: 0, pos: 15)\n",
      "  apple (weight: 1, pre: 1, pos: 3)\n",
      "    banana (weight: 1, pre: 2, pos: 2)\n",
      "      orange (weight: 1, pre: 3, pos: 1)\n",
      "  banana (weight: 2, pre: 4, pos: 7)\n",
      "    mango (weight: 1, pre: 5, pos: 4)\n",
      "    orange (weight: 1, pre: 6, pos: 6)\n",
      "      mango (weight: 1, pre: 7, pos: 5)\n",
      "  orange (weight: 1, pre: 8, pos: 10)\n",
      "    apple (weight: 1, pre: 9, pos: 9)\n",
      "      grape (weight: 1, pre: 10, pos: 8)\n",
      "  grape (weight: 1, pre: 11, pos: 14)\n",
      "    apple (weight: 1, pre: 12, pos: 13)\n",
      "      banana (weight: 1, pre: 13, pos: 12)\n",
      "        mango (weight: 1, pre: 14, pos: 11)\n"
     ]
    }
   ],
   "source": [
    "class SWNNode:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.weight = 0\n",
    "        self.pre = 0\n",
    "        self.pos = 0\n",
    "        self.parent = None\n",
    "        self.children = {}\n",
    "\n",
    "    def insert(self, T, weight):\n",
    "        if not T:\n",
    "            return\n",
    "        item = T[0]\n",
    "        if item in self.children:\n",
    "            child = self.children[item]\n",
    "            child.weight += weight\n",
    "        else:\n",
    "            child = SWNNode(item)\n",
    "            child.weight = weight\n",
    "            child.parent = self\n",
    "            self.children[item] = child\n",
    "        child.insert(T[1:], weight)\n",
    "\n",
    "class SWNTree:\n",
    "    def __init__(self):\n",
    "        self.root = SWNNode('null')\n",
    "\n",
    "    def construct_swn_tree(self, DB, tw):\n",
    "        for T in DB:\n",
    "            T = sorted(T, key=lambda x: x[1], reverse=True)\n",
    "            self.root.insert([item for item, weight in T], tw)\n",
    "        self.generate_pre_pos(self.root)\n",
    "\n",
    "    def generate_pre_pos(self, node, pre=0, pos=0):\n",
    "        node.pre = pre\n",
    "        node.pos = pos\n",
    "        for child in node.children.values():\n",
    "            pre, pos = self.generate_pre_pos(child, pre + 1, pos)\n",
    "        node.pos = pos + 1\n",
    "        return pre, pos + 1\n",
    "db = [\n",
    "    [('apple', 2), ('banana', 1), ('orange', 1)],\n",
    "    [('banana', 3), ('mango', 2)],\n",
    "    [('apple', 1), ('orange', 2), ('grape', 1)],\n",
    "    [('banana', 2), ('orange', 1), ('mango', 1)],\n",
    "    [('apple', 1), ('banana', 1), ('mango', 1), ('grape', 2)]\n",
    "]\n",
    "\n",
    "\n",
    "tw = 1\n",
    "swn_tree = SWNTree()\n",
    "swn_tree.construct_swn_tree(db, tw)\n",
    "\n",
    "# Print the SWN tree\n",
    "def print_tree(node, indent=0):\n",
    "    print('  ' * indent + f'{node.name} (weight: {node.weight}, pre: {node.pre}, pos: {node.pos})')\n",
    "    for child in node.children.values():\n",
    "        print_tree(child, indent + 1)\n",
    "\n",
    "print_tree(swn_tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
